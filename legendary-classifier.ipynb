{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imblearn\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Pokemon.csv'\n",
    "\n",
    "SEED = None\n",
    "ITERATIONS = 1000\n",
    "LEARNING_RATE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Pokemon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 samples with 13 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {df.shape[0]} samples with {df.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's preview the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's view the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['#', 'Name', 'Type 1', 'Type 2', 'Total', 'HP', 'Attack', 'Defense',\n",
       "       'Sp. Atk', 'Sp. Def', 'Speed', 'Generation', 'Legendary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = df.columns\n",
    "\n",
    "col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check distribution of target_class column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Legendary\n",
       "False    735\n",
       "True      65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Legendary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View summary of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   Name        800 non-null    object\n",
      " 2   Type 1      800 non-null    object\n",
      " 3   Type 2      414 non-null    object\n",
      " 4   Total       800 non-null    int64 \n",
      " 5   HP          800 non-null    int64 \n",
      " 6   Attack      800 non-null    int64 \n",
      " 7   Defense     800 non-null    int64 \n",
      " 8   Sp. Atk     800 non-null    int64 \n",
      " 9   Sp. Def     800 non-null    int64 \n",
      " 10  Speed       800 non-null    int64 \n",
      " 11  Generation  800 non-null    int64 \n",
      " 12  Legendary   800 non-null    bool  \n",
      "dtypes: bool(1), int64(9), object(3)\n",
      "memory usage: 75.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check of missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#               0\n",
       "Name            0\n",
       "Type 1          0\n",
       "Type 2        386\n",
       "Total           0\n",
       "HP              0\n",
       "Attack          0\n",
       "Defense         0\n",
       "Sp. Atk         0\n",
       "Sp. Def         0\n",
       "Speed           0\n",
       "Generation      0\n",
       "Legendary       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 2 missing is normal, not all pokemon has secondary type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unused features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>405</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>625</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>700</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>680</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total  Legendary\n",
       "0      318      False\n",
       "1      405      False\n",
       "2      525      False\n",
       "3      625      False\n",
       "4      309      False\n",
       "..     ...        ...\n",
       "795    600       True\n",
       "796    700       True\n",
       "797    600       True\n",
       "798    680       True\n",
       "799    600       True\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.drop(columns=['#', 'Name', 'Type 1', 'Type 2'],inplace=True)\n",
    "df.drop(columns=['#', 'Name', 'Type 1', 'Type 2', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Generation'],inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn boolean to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total  Legendary\n",
       "0      318          0\n",
       "1      405          0\n",
       "2      525          0\n",
       "3      625          0\n",
       "4      309          0\n",
       "..     ...        ...\n",
       "795    600          1\n",
       "796    700          1\n",
       "797    600          1\n",
       "798    680          1\n",
       "799    600          1\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Legendary'] = df['Legendary'].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just removing pseudo pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/xf02s8yx7yj7k0h2v83wcq2m0000gn/T/ipykernel_66192/4105114998.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Total'] = df['Total'] / 100\n"
     ]
    }
   ],
   "source": [
    "df = df[~((df['Legendary'] & (df['Total'] < 600)) | (~df['Legendary'] & (df['Total'] >= 600)))]\n",
    "df['Total'] = df['Total'] / 100  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare feature vector and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Legendary', axis=1)  # Drop the target column from features\n",
    "y = df['Legendary']  # Target column containing labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into separate training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>5.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total\n",
       "175   2.15\n",
       "710   6.60\n",
       "440   5.30\n",
       "754   3.41\n",
       "389   4.55\n",
       "..     ...\n",
       "325   3.80\n",
       "748   3.25\n",
       "405   3.30\n",
       "396   4.80\n",
       "591   5.45\n",
       "\n",
       "[593 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Legendary\n",
       "0    556\n",
       "1     37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>4.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>7.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>4.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total\n",
       "774   3.00\n",
       "26    2.62\n",
       "365   4.90\n",
       "424   7.70\n",
       "201   5.00\n",
       "..     ...\n",
       "354   5.60\n",
       "582   4.97\n",
       "735   3.69\n",
       "621   4.88\n",
       "395   3.00\n",
       "\n",
       "[149 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774    0\n",
       "26     0\n",
       "365    0\n",
       "424    1\n",
       "201    0\n",
       "      ..\n",
       "354    0\n",
       "582    0\n",
       "735    0\n",
       "621    0\n",
       "395    0\n",
       "Name: Legendary, Length: 149, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function and Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    # Class constructor\n",
    "    def __init__(self, alpha=1, iteration=1500):\n",
    "        self.w = None # Weights\n",
    "        self.n = None # No. of samples\n",
    "        self.b = 0\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        # Define the learning rate\n",
    "        self.alpha = alpha\n",
    "        # Define the iteration number\n",
    "        self.iteration = iteration\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        # print(f\"z = {z}\")\n",
    "        return 1 / (1 + 1 / np.exp(z))\n",
    "\n",
    "    # Class function to fit the data (find the appropiate value of w)\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        # Number of samples & number of features (dimensions)\n",
    "        self.n, d = X.shape\n",
    "        print(X.shape)\n",
    "\n",
    "        # Initialize w\n",
    "        self.w = np.zeros(d)\n",
    "\n",
    "        # Gradient Descent\n",
    "        for i in range(self.iteration):\n",
    "            print(f\"Epoch {i+1}/{self.iteration}\")\n",
    "            # Decrease learning rate when overshot\n",
    "            if not self.make_one_update():\n",
    "                self.alpha *= 0.1\n",
    "\n",
    "    def make_one_update(self):\n",
    "        w_current = self.w\n",
    "        b_current = self.b  \n",
    "\n",
    "        # Compute gradients\n",
    "        dw, db = self.compute_gradient(w_current, b_current)\n",
    "        # print(dw, db)       \n",
    "        step_w = (-1) * self.alpha * dw\n",
    "        step_b = (-1) * self.alpha * db\n",
    "        # print(step_b)\n",
    "\n",
    "        # Update weights and bias\n",
    "        w_update = w_current + step_w\n",
    "        b_update = b_current + step_b\n",
    "\n",
    "        current_loss = self.log_loss(w_current, b_current)\n",
    "        update_loss = self.log_loss(w_update, b_update)\n",
    "        \n",
    "        if current_loss > update_loss:\n",
    "            print(\"Loss decreases to \", update_loss)\n",
    "            self.w = w_update\n",
    "            self.b = b_update\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Loss increases to \", update_loss)\n",
    "            return False\n",
    "\n",
    "    def compute_gradient(self, w_current, b_current):\n",
    "        z = np.dot(self.X, w_current) + b_current\n",
    "        # Apply sigmoid function\n",
    "        y_prob = self.sigmoid(z)\n",
    "\n",
    "        # Compute gradients\n",
    "        dw = (1 / self.n) * np.dot(self.X.transpose(), (y_prob - self.y))\n",
    "        db = (1 / self.n) * np.sum(y_prob - self.y)\n",
    "\n",
    "        return dw, db\n",
    "    \n",
    "    def log_loss(self, w, b):\n",
    "        e = 1e-5\n",
    "        z = np.dot(self.X, w) + b\n",
    "        y_prob = self.sigmoid(z) + e\n",
    "        loss = (-1 / self.n) * np.sum(self.y * np.log(y_prob)           # if y = 1\n",
    "                              + (1 - self.y) * np.log(1 - y_prob))      # if y = 0\n",
    "        return loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.w) + self.b\n",
    "        y_pred = self.sigmoid(z)\n",
    "        y_pred_class = [1 if i >= 0.5 else 0 for i in y_pred]\n",
    "        return np.array(y_pred_class)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = np.mean(y_pred == y)\n",
    "        return accuracy\n",
    "\n",
    "    def probability_curve(self, X):\n",
    "        z = np.dot(X, self.w) + self.b\n",
    "        y_predicted = self.sigmoid(z)\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 1)\n",
      "Epoch 1/1000\n",
      "Loss increases to  0.7183537980298459\n",
      "Epoch 2/1000\n",
      "Loss decreases to  0.6745120140618241\n",
      "Epoch 3/1000\n",
      "Loss decreases to  0.5560841917673214\n",
      "Epoch 4/1000\n",
      "Loss decreases to  0.41536451159524035\n",
      "Epoch 5/1000\n",
      "Loss decreases to  0.3306968157485348\n",
      "Epoch 6/1000\n",
      "Loss decreases to  0.3214779437399216\n",
      "Epoch 7/1000\n",
      "Loss decreases to  0.3189322941222176\n",
      "Epoch 8/1000\n",
      "Loss decreases to  0.31665770094035656\n",
      "Epoch 9/1000\n",
      "Loss decreases to  0.31453637746379043\n",
      "Epoch 10/1000\n",
      "Loss decreases to  0.31246933684697215\n",
      "Epoch 11/1000\n",
      "Loss decreases to  0.3104358752242612\n",
      "Epoch 12/1000\n",
      "Loss decreases to  0.3084309163217795\n",
      "Epoch 13/1000\n",
      "Loss decreases to  0.30645135340603774\n",
      "Epoch 14/1000\n",
      "Loss decreases to  0.3044968855954515\n",
      "Epoch 15/1000\n",
      "Loss decreases to  0.30256668007555915\n",
      "Epoch 16/1000\n",
      "Loss decreases to  0.3006605283580884\n",
      "Epoch 17/1000\n",
      "Loss decreases to  0.2987779750534612\n",
      "Epoch 18/1000\n",
      "Loss decreases to  0.29691873929800344\n",
      "Epoch 19/1000\n",
      "Loss decreases to  0.2950824562435405\n",
      "Epoch 20/1000\n",
      "Loss decreases to  0.29326881756335293\n",
      "Epoch 21/1000\n",
      "Loss decreases to  0.2914774889126996\n",
      "Epoch 22/1000\n",
      "Loss decreases to  0.28970815702212993\n",
      "Epoch 23/1000\n",
      "Loss decreases to  0.2879605021156466\n",
      "Epoch 24/1000\n",
      "Loss decreases to  0.2862342140945308\n",
      "Epoch 25/1000\n",
      "Loss decreases to  0.2845289829932556\n",
      "Epoch 26/1000\n",
      "Loss decreases to  0.28284450470963485\n",
      "Epoch 27/1000\n",
      "Loss decreases to  0.2811804776003649\n",
      "Epoch 28/1000\n",
      "Loss decreases to  0.2795366045727665\n",
      "Epoch 29/1000\n",
      "Loss decreases to  0.277912591834867\n",
      "Epoch 30/1000\n",
      "Loss decreases to  0.27630814968069184\n",
      "Epoch 31/1000\n",
      "Loss decreases to  0.2747229920163498\n",
      "Epoch 32/1000\n",
      "Loss decreases to  0.2731568366600376\n",
      "Epoch 33/1000\n",
      "Loss decreases to  0.271609405153157\n",
      "Epoch 34/1000\n",
      "Loss decreases to  0.27008042287277195\n",
      "Epoch 35/1000\n",
      "Loss decreases to  0.2685696189481992\n",
      "Epoch 36/1000\n",
      "Loss decreases to  0.26707672629716833\n",
      "Epoch 37/1000\n",
      "Loss decreases to  0.2656014815806982\n",
      "Epoch 38/1000\n",
      "Loss decreases to  0.2641436252059093\n",
      "Epoch 39/1000\n",
      "Loss decreases to  0.2627029012936335\n",
      "Epoch 40/1000\n",
      "Loss decreases to  0.2612790576651217\n",
      "Epoch 41/1000\n",
      "Loss decreases to  0.25987184581264394\n",
      "Epoch 42/1000\n",
      "Loss decreases to  0.2584810208773881\n",
      "Epoch 43/1000\n",
      "Loss decreases to  0.25710634161944174\n",
      "Epoch 44/1000\n",
      "Loss decreases to  0.25574757039021473\n",
      "Epoch 45/1000\n",
      "Loss decreases to  0.2544044731006124\n",
      "Epoch 46/1000\n",
      "Loss decreases to  0.2530768191896778\n",
      "Epoch 47/1000\n",
      "Loss decreases to  0.25176438159072595\n",
      "Epoch 48/1000\n",
      "Loss decreases to  0.2504669366971941\n",
      "Epoch 49/1000\n",
      "Loss decreases to  0.2491842643268806\n",
      "Epoch 50/1000\n",
      "Loss decreases to  0.24791614768566392\n",
      "Epoch 51/1000\n",
      "Loss decreases to  0.24666237333012217\n",
      "Epoch 52/1000\n",
      "Loss decreases to  0.24542273112961727\n",
      "Epoch 53/1000\n",
      "Loss decreases to  0.24419701422760529\n",
      "Epoch 54/1000\n",
      "Loss decreases to  0.24298501900248573\n",
      "Epoch 55/1000\n",
      "Loss decreases to  0.24178654502790725\n",
      "Epoch 56/1000\n",
      "Loss decreases to  0.2406013950327177\n",
      "Epoch 57/1000\n",
      "Loss decreases to  0.2394293748605482\n",
      "Epoch 58/1000\n",
      "Loss decreases to  0.23827029342915282\n",
      "Epoch 59/1000\n",
      "Loss decreases to  0.23712396268952554\n",
      "Epoch 60/1000\n",
      "Loss decreases to  0.2359901975848797\n",
      "Epoch 61/1000\n",
      "Loss decreases to  0.23486881600952422\n",
      "Epoch 62/1000\n",
      "Loss decreases to  0.23375963876770053\n",
      "Epoch 63/1000\n",
      "Loss decreases to  0.23266248953241658\n",
      "Epoch 64/1000\n",
      "Loss decreases to  0.23157719480432992\n",
      "Epoch 65/1000\n",
      "Loss decreases to  0.23050358387071285\n",
      "Epoch 66/1000\n",
      "Loss decreases to  0.2294414887645442\n",
      "Epoch 67/1000\n",
      "Loss decreases to  0.22839074422375627\n",
      "Epoch 68/1000\n",
      "Loss decreases to  0.22735118765067447\n",
      "Epoch 69/1000\n",
      "Loss decreases to  0.22632265907167534\n",
      "Epoch 70/1000\n",
      "Loss decreases to  0.2253050010970933\n",
      "Epoch 71/1000\n",
      "Loss decreases to  0.2242980588813992\n",
      "Epoch 72/1000\n",
      "Loss decreases to  0.22330168008367582\n",
      "Epoch 73/1000\n",
      "Loss decreases to  0.22231571482840923\n",
      "Epoch 74/1000\n",
      "Loss decreases to  0.22134001566661723\n",
      "Epoch 75/1000\n",
      "Loss decreases to  0.22037443753733166\n",
      "Epoch 76/1000\n",
      "Loss decreases to  0.21941883772944976\n",
      "Epoch 77/1000\n",
      "Loss decreases to  0.21847307584397063\n",
      "Epoch 78/1000\n",
      "Loss decreases to  0.21753701375662757\n",
      "Epoch 79/1000\n",
      "Loss decreases to  0.21661051558092945\n",
      "Epoch 80/1000\n",
      "Loss decreases to  0.21569344763162057\n",
      "Epoch 81/1000\n",
      "Loss decreases to  0.21478567838856796\n",
      "Epoch 82/1000\n",
      "Loss decreases to  0.21388707846108393\n",
      "Epoch 83/1000\n",
      "Loss decreases to  0.21299752055269136\n",
      "Epoch 84/1000\n",
      "Loss decreases to  0.21211687942633625\n",
      "Epoch 85/1000\n",
      "Loss decreases to  0.21124503187005364\n",
      "Epoch 86/1000\n",
      "Loss decreases to  0.21038185666308987\n",
      "Epoch 87/1000\n",
      "Loss decreases to  0.209527234542485\n",
      "Epoch 88/1000\n",
      "Loss decreases to  0.20868104817011784\n",
      "Epoch 89/1000\n",
      "Loss decreases to  0.20784318210021419\n",
      "Epoch 90/1000\n",
      "Loss decreases to  0.20701352274732132\n",
      "Epoch 91/1000\n",
      "Loss decreases to  0.20619195835474693\n",
      "Epoch 92/1000\n",
      "Loss decreases to  0.20537837896346428\n",
      "Epoch 93/1000\n",
      "Loss decreases to  0.2045726763814817\n",
      "Epoch 94/1000\n",
      "Loss decreases to  0.20377474415367586\n",
      "Epoch 95/1000\n",
      "Loss decreases to  0.2029844775320871\n",
      "Epoch 96/1000\n",
      "Loss decreases to  0.20220177344667484\n",
      "Epoch 97/1000\n",
      "Loss decreases to  0.20142653047653067\n",
      "Epoch 98/1000\n",
      "Loss decreases to  0.20065864882154655\n",
      "Epoch 99/1000\n",
      "Loss decreases to  0.19989803027453484\n",
      "Epoch 100/1000\n",
      "Loss decreases to  0.19914457819379694\n",
      "Epoch 101/1000\n",
      "Loss decreases to  0.19839819747613735\n",
      "Epoch 102/1000\n",
      "Loss decreases to  0.19765879453031837\n",
      "Epoch 103/1000\n",
      "Loss decreases to  0.1969262772509526\n",
      "Epoch 104/1000\n",
      "Loss decreases to  0.19620055499282799\n",
      "Epoch 105/1000\n",
      "Loss decreases to  0.1954815385456613\n",
      "Epoch 106/1000\n",
      "Loss decreases to  0.19476914010927623\n",
      "Epoch 107/1000\n",
      "Loss decreases to  0.19406327326919964\n",
      "Epoch 108/1000\n",
      "Loss decreases to  0.19336385297267317\n",
      "Epoch 109/1000\n",
      "Loss decreases to  0.19267079550507363\n",
      "Epoch 110/1000\n",
      "Loss decreases to  0.19198401846673802\n",
      "Epoch 111/1000\n",
      "Loss decreases to  0.19130344075018774\n",
      "Epoch 112/1000\n",
      "Loss decreases to  0.19062898251774668\n",
      "Epoch 113/1000\n",
      "Loss decreases to  0.18996056517954818\n",
      "Epoch 114/1000\n",
      "Loss decreases to  0.18929811137192548\n",
      "Epoch 115/1000\n",
      "Loss decreases to  0.18864154493618018\n",
      "Epoch 116/1000\n",
      "Loss decreases to  0.18799079089772325\n",
      "Epoch 117/1000\n",
      "Loss decreases to  0.1873457754455838\n",
      "Epoch 118/1000\n",
      "Loss decreases to  0.18670642591227926\n",
      "Epoch 119/1000\n",
      "Loss decreases to  0.18607267075404224\n",
      "Epoch 120/1000\n",
      "Loss decreases to  0.18544443953139864\n",
      "Epoch 121/1000\n",
      "Loss decreases to  0.1848216628900911\n",
      "Epoch 122/1000\n",
      "Loss decreases to  0.18420427254234323\n",
      "Epoch 123/1000\n",
      "Loss decreases to  0.18359220124845788\n",
      "Epoch 124/1000\n",
      "Loss decreases to  0.18298538279874604\n",
      "Epoch 125/1000\n",
      "Loss decreases to  0.18238375199577928\n",
      "Epoch 126/1000\n",
      "Loss decreases to  0.1817872446369613\n",
      "Epoch 127/1000\n",
      "Loss decreases to  0.18119579749741327\n",
      "Epoch 128/1000\n",
      "Loss decreases to  0.18060934831316777\n",
      "Epoch 129/1000\n",
      "Loss decreases to  0.1800278357646659\n",
      "Epoch 130/1000\n",
      "Loss decreases to  0.1794511994605527\n",
      "Epoch 131/1000\n",
      "Loss decreases to  0.17887937992176586\n",
      "Epoch 132/1000\n",
      "Loss decreases to  0.17831231856591223\n",
      "Epoch 133/1000\n",
      "Loss decreases to  0.17774995769192795\n",
      "Epoch 134/1000\n",
      "Loss decreases to  0.1771922404650168\n",
      "Epoch 135/1000\n",
      "Loss decreases to  0.17663911090186152\n",
      "Epoch 136/1000\n",
      "Loss decreases to  0.1760905138561043\n",
      "Epoch 137/1000\n",
      "Loss decreases to  0.17554639500409108\n",
      "Epoch 138/1000\n",
      "Loss decreases to  0.1750067008308748\n",
      "Epoch 139/1000\n",
      "Loss decreases to  0.1744713786164736\n",
      "Epoch 140/1000\n",
      "Loss decreases to  0.17394037642237878\n",
      "Epoch 141/1000\n",
      "Loss decreases to  0.17341364307830875\n",
      "Epoch 142/1000\n",
      "Loss decreases to  0.1728911281692037\n",
      "Epoch 143/1000\n",
      "Loss decreases to  0.1723727820224574\n",
      "Epoch 144/1000\n",
      "Loss decreases to  0.17185855569538133\n",
      "Epoch 145/1000\n",
      "Loss decreases to  0.17134840096289694\n",
      "Epoch 146/1000\n",
      "Loss decreases to  0.1708422703054528\n",
      "Epoch 147/1000\n",
      "Loss decreases to  0.17034011689716033\n",
      "Epoch 148/1000\n",
      "Loss decreases to  0.16984189459414695\n",
      "Epoch 149/1000\n",
      "Loss decreases to  0.1693475579231203\n",
      "Epoch 150/1000\n",
      "Loss decreases to  0.16885706207014092\n",
      "Epoch 151/1000\n",
      "Loss decreases to  0.16837036286959886\n",
      "Epoch 152/1000\n",
      "Loss decreases to  0.16788741679339111\n",
      "Epoch 153/1000\n",
      "Loss decreases to  0.16740818094029547\n",
      "Epoch 154/1000\n",
      "Loss decreases to  0.16693261302553752\n",
      "Epoch 155/1000\n",
      "Loss decreases to  0.16646067137054715\n",
      "Epoch 156/1000\n",
      "Loss decreases to  0.16599231489290078\n",
      "Epoch 157/1000\n",
      "Loss decreases to  0.16552750309644637\n",
      "Epoch 158/1000\n",
      "Loss decreases to  0.1650661960616071\n",
      "Epoch 159/1000\n",
      "Loss decreases to  0.16460835443586094\n",
      "Epoch 160/1000\n",
      "Loss decreases to  0.16415393942439266\n",
      "Epoch 161/1000\n",
      "Loss decreases to  0.16370291278091453\n",
      "Epoch 162/1000\n",
      "Loss decreases to  0.16325523679865359\n",
      "Epoch 163/1000\n",
      "Loss decreases to  0.1628108743015013\n",
      "Epoch 164/1000\n",
      "Loss decreases to  0.16236978863532306\n",
      "Epoch 165/1000\n",
      "Loss decreases to  0.1619319436594246\n",
      "Epoch 166/1000\n",
      "Loss decreases to  0.16149730373817195\n",
      "Epoch 167/1000\n",
      "Loss decreases to  0.1610658337327625\n",
      "Epoch 168/1000\n",
      "Loss decreases to  0.16063749899314386\n",
      "Epoch 169/1000\n",
      "Loss decreases to  0.16021226535007815\n",
      "Epoch 170/1000\n",
      "Loss decreases to  0.15979009910734865\n",
      "Epoch 171/1000\n",
      "Loss decreases to  0.15937096703410653\n",
      "Epoch 172/1000\n",
      "Loss decreases to  0.158954836357354\n",
      "Epoch 173/1000\n",
      "Loss decreases to  0.15854167475456296\n",
      "Epoch 174/1000\n",
      "Loss decreases to  0.158131450346425\n",
      "Epoch 175/1000\n",
      "Loss decreases to  0.15772413168973096\n",
      "Epoch 176/1000\n",
      "Loss decreases to  0.15731968777037786\n",
      "Epoch 177/1000\n",
      "Loss decreases to  0.15691808799650012\n",
      "Epoch 178/1000\n",
      "Loss decreases to  0.15651930219172336\n",
      "Epoch 179/1000\n",
      "Loss decreases to  0.15612330058853785\n",
      "Epoch 180/1000\n",
      "Loss decreases to  0.1557300538217899\n",
      "Epoch 181/1000\n",
      "Loss decreases to  0.15533953292228872\n",
      "Epoch 182/1000\n",
      "Loss decreases to  0.15495170931052643\n",
      "Epoch 183/1000\n",
      "Loss decreases to  0.1545665547905091\n",
      "Epoch 184/1000\n",
      "Loss decreases to  0.1541840415436972\n",
      "Epoch 185/1000\n",
      "Loss decreases to  0.15380414212305274\n",
      "Epoch 186/1000\n",
      "Loss decreases to  0.15342682944719135\n",
      "Epoch 187/1000\n",
      "Loss decreases to  0.15305207679463753\n",
      "Epoch 188/1000\n",
      "Loss decreases to  0.15267985779818072\n",
      "Epoch 189/1000\n",
      "Loss decreases to  0.15231014643933058\n",
      "Epoch 190/1000\n",
      "Loss decreases to  0.1519429170428695\n",
      "Epoch 191/1000\n",
      "Loss decreases to  0.15157814427150054\n",
      "Epoch 192/1000\n",
      "Loss decreases to  0.1512158031205889\n",
      "Epoch 193/1000\n",
      "Loss decreases to  0.15085586891299538\n",
      "Epoch 194/1000\n",
      "Loss decreases to  0.15049831729399984\n",
      "Epoch 195/1000\n",
      "Loss decreases to  0.15014312422631312\n",
      "Epoch 196/1000\n",
      "Loss decreases to  0.14979026598517578\n",
      "Epoch 197/1000\n",
      "Loss decreases to  0.14943971915354176\n",
      "Epoch 198/1000\n",
      "Loss decreases to  0.14909146061734596\n",
      "Epoch 199/1000\n",
      "Loss decreases to  0.1487454675608533\n",
      "Epoch 200/1000\n",
      "Loss decreases to  0.1484017174620887\n",
      "Epoch 201/1000\n",
      "Loss decreases to  0.14806018808834548\n",
      "Epoch 202/1000\n",
      "Loss decreases to  0.14772085749177175\n",
      "Epoch 203/1000\n",
      "Loss decreases to  0.1473837040050322\n",
      "Epoch 204/1000\n",
      "Loss decreases to  0.14704870623704505\n",
      "Epoch 205/1000\n",
      "Loss decreases to  0.14671584306879165\n",
      "Epoch 206/1000\n",
      "Loss decreases to  0.1463850936491984\n",
      "Epoch 207/1000\n",
      "Loss decreases to  0.14605643739108864\n",
      "Epoch 208/1000\n",
      "Loss decreases to  0.14572985396720425\n",
      "Epoch 209/1000\n",
      "Loss decreases to  0.1454053233062944\n",
      "Epoch 210/1000\n",
      "Loss decreases to  0.14508282558927188\n",
      "Epoch 211/1000\n",
      "Loss decreases to  0.14476234124543394\n",
      "Epoch 212/1000\n",
      "Loss decreases to  0.14444385094874773\n",
      "Epoch 213/1000\n",
      "Loss decreases to  0.14412733561419863\n",
      "Epoch 214/1000\n",
      "Loss decreases to  0.14381277639420031\n",
      "Epoch 215/1000\n",
      "Loss decreases to  0.14350015467506577\n",
      "Epoch 216/1000\n",
      "Loss decreases to  0.1431894520735375\n",
      "Epoch 217/1000\n",
      "Loss decreases to  0.14288065043337628\n",
      "Epoch 218/1000\n",
      "Loss decreases to  0.14257373182200742\n",
      "Epoch 219/1000\n",
      "Loss decreases to  0.1422686785272233\n",
      "Epoch 220/1000\n",
      "Loss decreases to  0.1419654730539411\n",
      "Epoch 221/1000\n",
      "Loss decreases to  0.14166409812101477\n",
      "Epoch 222/1000\n",
      "Loss decreases to  0.1413645366581004\n",
      "Epoch 223/1000\n",
      "Loss decreases to  0.14106677180257382\n",
      "Epoch 224/1000\n",
      "Loss decreases to  0.14077078689649944\n",
      "Epoch 225/1000\n",
      "Loss decreases to  0.14047656548364987\n",
      "Epoch 226/1000\n",
      "Loss decreases to  0.14018409130657425\n",
      "Epoch 227/1000\n",
      "Loss decreases to  0.13989334830371603\n",
      "Epoch 228/1000\n",
      "Loss decreases to  0.1396043206065778\n",
      "Epoch 229/1000\n",
      "Loss decreases to  0.13931699253693325\n",
      "Epoch 230/1000\n",
      "Loss decreases to  0.13903134860408511\n",
      "Epoch 231/1000\n",
      "Loss decreases to  0.13874737350216795\n",
      "Epoch 232/1000\n",
      "Loss decreases to  0.13846505210749546\n",
      "Epoch 233/1000\n",
      "Loss decreases to  0.13818436947595159\n",
      "Epoch 234/1000\n",
      "Loss decreases to  0.13790531084042362\n",
      "Epoch 235/1000\n",
      "Loss decreases to  0.13762786160827808\n",
      "Epoch 236/1000\n",
      "Loss decreases to  0.13735200735887712\n",
      "Epoch 237/1000\n",
      "Loss decreases to  0.13707773384113586\n",
      "Epoch 238/1000\n",
      "Loss decreases to  0.1368050269711191\n",
      "Epoch 239/1000\n",
      "Loss decreases to  0.13653387282967733\n",
      "Epoch 240/1000\n",
      "Loss decreases to  0.1362642576601209\n",
      "Epoch 241/1000\n",
      "Loss decreases to  0.1359961678659318\n",
      "Epoch 242/1000\n",
      "Loss decreases to  0.13572959000851248\n",
      "Epoch 243/1000\n",
      "Loss decreases to  0.13546451080497082\n",
      "Epoch 244/1000\n",
      "Loss decreases to  0.13520091712594115\n",
      "Epoch 245/1000\n",
      "Loss decreases to  0.13493879599343955\n",
      "Epoch 246/1000\n",
      "Loss decreases to  0.13467813457875435\n",
      "Epoch 247/1000\n",
      "Loss decreases to  0.13441892020036975\n",
      "Epoch 248/1000\n",
      "Loss decreases to  0.13416114032192297\n",
      "Epoch 249/1000\n",
      "Loss decreases to  0.1339047825501942\n",
      "Epoch 250/1000\n",
      "Loss decreases to  0.13364983463312763\n",
      "Epoch 251/1000\n",
      "Loss decreases to  0.13339628445788518\n",
      "Epoch 252/1000\n",
      "Loss decreases to  0.1331441200489303\n",
      "Epoch 253/1000\n",
      "Loss decreases to  0.13289332956614208\n",
      "Epoch 254/1000\n",
      "Loss decreases to  0.13264390130295992\n",
      "Epoch 255/1000\n",
      "Loss decreases to  0.13239582368455646\n",
      "Epoch 256/1000\n",
      "Loss decreases to  0.1321490852660402\n",
      "Epoch 257/1000\n",
      "Loss decreases to  0.13190367473068576\n",
      "Epoch 258/1000\n",
      "Loss decreases to  0.13165958088819232\n",
      "Epoch 259/1000\n",
      "Loss decreases to  0.13141679267296913\n",
      "Epoch 260/1000\n",
      "Loss decreases to  0.13117529914244783\n",
      "Epoch 261/1000\n",
      "Loss decreases to  0.13093508947542132\n",
      "Epoch 262/1000\n",
      "Loss decreases to  0.1306961529704082\n",
      "Epoch 263/1000\n",
      "Loss decreases to  0.130458479044043\n",
      "Epoch 264/1000\n",
      "Loss decreases to  0.1302220572294912\n",
      "Epoch 265/1000\n",
      "Loss decreases to  0.12998687717488883\n",
      "Epoch 266/1000\n",
      "Loss decreases to  0.12975292864180613\n",
      "Epoch 267/1000\n",
      "Loss decreases to  0.1295202015037353\n",
      "Epoch 268/1000\n",
      "Loss decreases to  0.1292886857446011\n",
      "Epoch 269/1000\n",
      "Loss decreases to  0.12905837145729462\n",
      "Epoch 270/1000\n",
      "Loss decreases to  0.1288292488422295\n",
      "Epoch 271/1000\n",
      "Loss decreases to  0.1286013082059205\n",
      "Epoch 272/1000\n",
      "Loss decreases to  0.12837453995958328\n",
      "Epoch 273/1000\n",
      "Loss decreases to  0.12814893461775625\n",
      "Epoch 274/1000\n",
      "Loss decreases to  0.1279244827969429\n",
      "Epoch 275/1000\n",
      "Loss decreases to  0.12770117521427504\n",
      "Epoch 276/1000\n",
      "Loss decreases to  0.12747900268619639\n",
      "Epoch 277/1000\n",
      "Loss decreases to  0.1272579561271658\n",
      "Epoch 278/1000\n",
      "Loss decreases to  0.1270380265483807\n",
      "Epoch 279/1000\n",
      "Loss decreases to  0.12681920505651917\n",
      "Epoch 280/1000\n",
      "Loss decreases to  0.12660148285250128\n",
      "Epoch 281/1000\n",
      "Loss decreases to  0.12638485123026932\n",
      "Epoch 282/1000\n",
      "Loss decreases to  0.1261693015755859\n",
      "Epoch 283/1000\n",
      "Loss decreases to  0.1259548253648504\n",
      "Epoch 284/1000\n",
      "Loss decreases to  0.12574141416393284\n",
      "Epoch 285/1000\n",
      "Loss decreases to  0.12552905962702557\n",
      "Epoch 286/1000\n",
      "Loss decreases to  0.12531775349551175\n",
      "Epoch 287/1000\n",
      "Loss decreases to  0.12510748759685086\n",
      "Epoch 288/1000\n",
      "Loss decreases to  0.12489825384348055\n",
      "Epoch 289/1000\n",
      "Loss decreases to  0.1246900442317351\n",
      "Epoch 290/1000\n",
      "Loss decreases to  0.12448285084077965\n",
      "Epoch 291/1000\n",
      "Loss decreases to  0.12427666583156019\n",
      "Epoch 292/1000\n",
      "Loss decreases to  0.12407148144576917\n",
      "Epoch 293/1000\n",
      "Loss decreases to  0.12386729000482619\n",
      "Epoch 294/1000\n",
      "Loss decreases to  0.1236640839088738\n",
      "Epoch 295/1000\n",
      "Loss decreases to  0.1234618556357879\n",
      "Epoch 296/1000\n",
      "Loss decreases to  0.12326059774020272\n",
      "Epoch 297/1000\n",
      "Loss decreases to  0.12306030285255001\n",
      "Epoch 298/1000\n",
      "Loss decreases to  0.12286096367811221\n",
      "Epoch 299/1000\n",
      "Loss decreases to  0.12266257299608954\n",
      "Epoch 300/1000\n",
      "Loss decreases to  0.12246512365868044\n",
      "Epoch 301/1000\n",
      "Loss decreases to  0.12226860859017545\n",
      "Epoch 302/1000\n",
      "Loss decreases to  0.12207302078606433\n",
      "Epoch 303/1000\n",
      "Loss decreases to  0.12187835331215581\n",
      "Epoch 304/1000\n",
      "Loss decreases to  0.12168459930371031\n",
      "Epoch 305/1000\n",
      "Loss decreases to  0.12149175196458502\n",
      "Epoch 306/1000\n",
      "Loss decreases to  0.1212998045663911\n",
      "Epoch 307/1000\n",
      "Loss decreases to  0.12110875044766335\n",
      "Epoch 308/1000\n",
      "Loss decreases to  0.12091858301304143\n",
      "Epoch 309/1000\n",
      "Loss decreases to  0.12072929573246287\n",
      "Epoch 310/1000\n",
      "Loss decreases to  0.12054088214036777\n",
      "Epoch 311/1000\n",
      "Loss decreases to  0.12035333583491457\n",
      "Epoch 312/1000\n",
      "Loss decreases to  0.12016665047720695\n",
      "Epoch 313/1000\n",
      "Loss decreases to  0.11998081979053207\n",
      "Epoch 314/1000\n",
      "Loss decreases to  0.11979583755960908\n",
      "Epoch 315/1000\n",
      "Loss decreases to  0.11961169762984872\n",
      "Epoch 316/1000\n",
      "Loss decreases to  0.11942839390662295\n",
      "Epoch 317/1000\n",
      "Loss decreases to  0.11924592035454519\n",
      "Epoch 318/1000\n",
      "Loss decreases to  0.11906427099676048\n",
      "Epoch 319/1000\n",
      "Loss decreases to  0.11888343991424569\n",
      "Epoch 320/1000\n",
      "Loss decreases to  0.1187034212451193\n",
      "Epoch 321/1000\n",
      "Loss decreases to  0.11852420918396145\n",
      "Epoch 322/1000\n",
      "Loss decreases to  0.11834579798114252\n",
      "Epoch 323/1000\n",
      "Loss decreases to  0.11816818194216194\n",
      "Epoch 324/1000\n",
      "Loss decreases to  0.1179913554269957\n",
      "Epoch 325/1000\n",
      "Loss decreases to  0.11781531284945293\n",
      "Epoch 326/1000\n",
      "Loss decreases to  0.11764004867654165\n",
      "Epoch 327/1000\n",
      "Loss decreases to  0.11746555742784309\n",
      "Epoch 328/1000\n",
      "Loss decreases to  0.1172918336748946\n",
      "Epoch 329/1000\n",
      "Loss decreases to  0.11711887204058109\n",
      "Epoch 330/1000\n",
      "Loss decreases to  0.116946667198535\n",
      "Epoch 331/1000\n",
      "Loss decreases to  0.11677521387254433\n",
      "Epoch 332/1000\n",
      "Loss decreases to  0.1166045068359687\n",
      "Epoch 333/1000\n",
      "Loss decreases to  0.11643454091116358\n",
      "Epoch 334/1000\n",
      "Loss decreases to  0.11626531096891238\n",
      "Epoch 335/1000\n",
      "Loss decreases to  0.11609681192786596\n",
      "Epoch 336/1000\n",
      "Loss decreases to  0.11592903875399022\n",
      "Epoch 337/1000\n",
      "Loss decreases to  0.11576198646002071\n",
      "Epoch 338/1000\n",
      "Loss decreases to  0.11559565010492506\n",
      "Epoch 339/1000\n",
      "Loss decreases to  0.11543002479337236\n",
      "Epoch 340/1000\n",
      "Loss decreases to  0.11526510567520971\n",
      "Epoch 341/1000\n",
      "Loss decreases to  0.11510088794494619\n",
      "Epoch 342/1000\n",
      "Loss decreases to  0.11493736684124314\n",
      "Epoch 343/1000\n",
      "Loss decreases to  0.11477453764641202\n",
      "Epoch 344/1000\n",
      "Loss decreases to  0.11461239568591809\n",
      "Epoch 345/1000\n",
      "Loss decreases to  0.11445093632789163\n",
      "Epoch 346/1000\n",
      "Loss decreases to  0.11429015498264529\n",
      "Epoch 347/1000\n",
      "Loss decreases to  0.11413004710219742\n",
      "Epoch 348/1000\n",
      "Loss decreases to  0.11397060817980267\n",
      "Epoch 349/1000\n",
      "Loss decreases to  0.11381183374948808\n",
      "Epoch 350/1000\n",
      "Loss decreases to  0.1136537193855954\n",
      "Epoch 351/1000\n",
      "Loss decreases to  0.11349626070232993\n",
      "Epoch 352/1000\n",
      "Loss decreases to  0.1133394533533147\n",
      "Epoch 353/1000\n",
      "Loss decreases to  0.11318329303115107\n",
      "Epoch 354/1000\n",
      "Loss decreases to  0.11302777546698452\n",
      "Epoch 355/1000\n",
      "Loss decreases to  0.11287289643007672\n",
      "Epoch 356/1000\n",
      "Loss decreases to  0.1127186517273828\n",
      "Epoch 357/1000\n",
      "Loss decreases to  0.11256503720313435\n",
      "Epoch 358/1000\n",
      "Loss decreases to  0.11241204873842772\n",
      "Epoch 359/1000\n",
      "Loss decreases to  0.1122596822508178\n",
      "Epoch 360/1000\n",
      "Loss decreases to  0.11210793369391707\n",
      "Epoch 361/1000\n",
      "Loss decreases to  0.11195679905699982\n",
      "Epoch 362/1000\n",
      "Loss decreases to  0.11180627436461135\n",
      "Epoch 363/1000\n",
      "Loss decreases to  0.11165635567618253\n",
      "Epoch 364/1000\n",
      "Loss decreases to  0.111507039085649\n",
      "Epoch 365/1000\n",
      "Loss decreases to  0.11135832072107574\n",
      "Epoch 366/1000\n",
      "Loss decreases to  0.11121019674428577\n",
      "Epoch 367/1000\n",
      "Loss decreases to  0.11106266335049432\n",
      "Epoch 368/1000\n",
      "Loss decreases to  0.11091571676794722\n",
      "Epoch 369/1000\n",
      "Loss decreases to  0.11076935325756412\n",
      "Epoch 370/1000\n",
      "Loss decreases to  0.11062356911258626\n",
      "Epoch 371/1000\n",
      "Loss decreases to  0.11047836065822861\n",
      "Epoch 372/1000\n",
      "Loss decreases to  0.1103337242513365\n",
      "Epoch 373/1000\n",
      "Loss decreases to  0.11018965628004668\n",
      "Epoch 374/1000\n",
      "Loss decreases to  0.11004615316345251\n",
      "Epoch 375/1000\n",
      "Loss decreases to  0.10990321135127365\n",
      "Epoch 376/1000\n",
      "Loss decreases to  0.10976082732352943\n",
      "Epoch 377/1000\n",
      "Loss decreases to  0.10961899759021715\n",
      "Epoch 378/1000\n",
      "Loss decreases to  0.10947771869099335\n",
      "Epoch 379/1000\n",
      "Loss decreases to  0.1093369871948602\n",
      "Epoch 380/1000\n",
      "Loss decreases to  0.10919679969985487\n",
      "Epoch 381/1000\n",
      "Loss decreases to  0.10905715283274342\n",
      "Epoch 382/1000\n",
      "Loss decreases to  0.10891804324871829\n",
      "Epoch 383/1000\n",
      "Loss decreases to  0.10877946763109939\n",
      "Epoch 384/1000\n",
      "Loss decreases to  0.10864142269103932\n",
      "Epoch 385/1000\n",
      "Loss decreases to  0.10850390516723182\n",
      "Epoch 386/1000\n",
      "Loss decreases to  0.10836691182562415\n",
      "Epoch 387/1000\n",
      "Loss decreases to  0.10823043945913269\n",
      "Epoch 388/1000\n",
      "Loss decreases to  0.10809448488736259\n",
      "Epoch 389/1000\n",
      "Loss decreases to  0.1079590449563303\n",
      "Epoch 390/1000\n",
      "Loss decreases to  0.10782411653818981\n",
      "Epoch 391/1000\n",
      "Loss decreases to  0.10768969653096234\n",
      "Epoch 392/1000\n",
      "Loss decreases to  0.1075557818582691\n",
      "Epoch 393/1000\n",
      "Loss decreases to  0.1074223694690674\n",
      "Epoch 394/1000\n",
      "Loss decreases to  0.10728945633739007\n",
      "Epoch 395/1000\n",
      "Loss decreases to  0.10715703946208809\n",
      "Epoch 396/1000\n",
      "Loss decreases to  0.1070251158665761\n",
      "Epoch 397/1000\n",
      "Loss decreases to  0.10689368259858135\n",
      "Epoch 398/1000\n",
      "Loss decreases to  0.10676273672989542\n",
      "Epoch 399/1000\n",
      "Loss decreases to  0.10663227535612899\n",
      "Epoch 400/1000\n",
      "Loss decreases to  0.10650229559646979\n",
      "Epoch 401/1000\n",
      "Loss decreases to  0.1063727945934431\n",
      "Epoch 402/1000\n",
      "Loss decreases to  0.10624376951267568\n",
      "Epoch 403/1000\n",
      "Loss decreases to  0.1061152175426618\n",
      "Epoch 404/1000\n",
      "Loss decreases to  0.10598713589453271\n",
      "Epoch 405/1000\n",
      "Loss decreases to  0.10585952180182866\n",
      "Epoch 406/1000\n",
      "Loss decreases to  0.10573237252027352\n",
      "Epoch 407/1000\n",
      "Loss decreases to  0.10560568532755231\n",
      "Epoch 408/1000\n",
      "Loss decreases to  0.10547945752309108\n",
      "Epoch 409/1000\n",
      "Loss decreases to  0.10535368642783995\n",
      "Epoch 410/1000\n",
      "Loss decreases to  0.10522836938405797\n",
      "Epoch 411/1000\n",
      "Loss decreases to  0.10510350375510122\n",
      "Epoch 412/1000\n",
      "Loss decreases to  0.10497908692521297\n",
      "Epoch 413/1000\n",
      "Loss decreases to  0.10485511629931667\n",
      "Epoch 414/1000\n",
      "Loss decreases to  0.10473158930281092\n",
      "Epoch 415/1000\n",
      "Loss decreases to  0.10460850338136732\n",
      "Epoch 416/1000\n",
      "Loss decreases to  0.10448585600073057\n",
      "Epoch 417/1000\n",
      "Loss decreases to  0.10436364464652058\n",
      "Epoch 418/1000\n",
      "Loss decreases to  0.10424186682403737\n",
      "Epoch 419/1000\n",
      "Loss decreases to  0.10412052005806799\n",
      "Epoch 420/1000\n",
      "Loss decreases to  0.1039996018926957\n",
      "Epoch 421/1000\n",
      "Loss decreases to  0.10387910989111153\n",
      "Epoch 422/1000\n",
      "Loss decreases to  0.10375904163542768\n",
      "Epoch 423/1000\n",
      "Loss decreases to  0.10363939472649362\n",
      "Epoch 424/1000\n",
      "Loss decreases to  0.10352016678371387\n",
      "Epoch 425/1000\n",
      "Loss decreases to  0.10340135544486796\n",
      "Epoch 426/1000\n",
      "Loss decreases to  0.10328295836593271\n",
      "Epoch 427/1000\n",
      "Loss decreases to  0.10316497322090629\n",
      "Epoch 428/1000\n",
      "Loss decreases to  0.10304739770163444\n",
      "Epoch 429/1000\n",
      "Loss decreases to  0.10293022951763872\n",
      "Epoch 430/1000\n",
      "Loss decreases to  0.10281346639594653\n",
      "Epoch 431/1000\n",
      "Loss decreases to  0.10269710608092326\n",
      "Epoch 432/1000\n",
      "Loss decreases to  0.10258114633410644\n",
      "Epoch 433/1000\n",
      "Loss decreases to  0.10246558493404141\n",
      "Epoch 434/1000\n",
      "Loss decreases to  0.10235041967611931\n",
      "Epoch 435/1000\n",
      "Loss decreases to  0.10223564837241651\n",
      "Epoch 436/1000\n",
      "Loss decreases to  0.10212126885153633\n",
      "Epoch 437/1000\n",
      "Loss decreases to  0.10200727895845194\n",
      "Epoch 438/1000\n",
      "Loss decreases to  0.10189367655435151\n",
      "Epoch 439/1000\n",
      "Loss decreases to  0.10178045951648518\n",
      "Epoch 440/1000\n",
      "Loss decreases to  0.10166762573801315\n",
      "Epoch 441/1000\n",
      "Loss decreases to  0.10155517312785618\n",
      "Epoch 442/1000\n",
      "Loss decreases to  0.10144309961054727\n",
      "Epoch 443/1000\n",
      "Loss decreases to  0.10133140312608531\n",
      "Epoch 444/1000\n",
      "Loss decreases to  0.10122008162979024\n",
      "Epoch 445/1000\n",
      "Loss decreases to  0.10110913309215976\n",
      "Epoch 446/1000\n",
      "Loss decreases to  0.10099855549872772\n",
      "Epoch 447/1000\n",
      "Loss decreases to  0.10088834684992418\n",
      "Epoch 448/1000\n",
      "Loss decreases to  0.10077850516093682\n",
      "Epoch 449/1000\n",
      "Loss decreases to  0.10066902846157406\n",
      "Epoch 450/1000\n",
      "Loss decreases to  0.10055991479612963\n",
      "Epoch 451/1000\n",
      "Loss decreases to  0.10045116222324851\n",
      "Epoch 452/1000\n",
      "Loss decreases to  0.1003427688157947\n",
      "Epoch 453/1000\n",
      "Loss decreases to  0.10023473266071999\n",
      "Epoch 454/1000\n",
      "Loss decreases to  0.10012705185893457\n",
      "Epoch 455/1000\n",
      "Loss decreases to  0.10001972452517875\n",
      "Epoch 456/1000\n",
      "Loss decreases to  0.09991274878789652\n",
      "Epoch 457/1000\n",
      "Loss decreases to  0.09980612278910982\n",
      "Epoch 458/1000\n",
      "Loss decreases to  0.0996998446842948\n",
      "Epoch 459/1000\n",
      "Loss decreases to  0.09959391264225917\n",
      "Epoch 460/1000\n",
      "Loss decreases to  0.09948832484502093\n",
      "Epoch 461/1000\n",
      "Loss decreases to  0.0993830794876883\n",
      "Epoch 462/1000\n",
      "Loss decreases to  0.09927817477834124\n",
      "Epoch 463/1000\n",
      "Loss decreases to  0.09917360893791378\n",
      "Epoch 464/1000\n",
      "Loss decreases to  0.09906938020007824\n",
      "Epoch 465/1000\n",
      "Loss decreases to  0.09896548681113018\n",
      "Epoch 466/1000\n",
      "Loss decreases to  0.09886192702987481\n",
      "Epoch 467/1000\n",
      "Loss decreases to  0.09875869912751459\n",
      "Epoch 468/1000\n",
      "Loss decreases to  0.09865580138753802\n",
      "Epoch 469/1000\n",
      "Loss decreases to  0.09855323210560975\n",
      "Epoch 470/1000\n",
      "Loss decreases to  0.09845098958946166\n",
      "Epoch 471/1000\n",
      "Loss decreases to  0.09834907215878513\n",
      "Epoch 472/1000\n",
      "Loss decreases to  0.09824747814512483\n",
      "Epoch 473/1000\n",
      "Loss decreases to  0.09814620589177295\n",
      "Epoch 474/1000\n",
      "Loss decreases to  0.09804525375366523\n",
      "Epoch 475/1000\n",
      "Loss decreases to  0.09794462009727777\n",
      "Epoch 476/1000\n",
      "Loss decreases to  0.09784430330052485\n",
      "Epoch 477/1000\n",
      "Loss decreases to  0.09774430175265807\n",
      "Epoch 478/1000\n",
      "Loss decreases to  0.09764461385416638\n",
      "Epoch 479/1000\n",
      "Loss decreases to  0.09754523801667736\n",
      "Epoch 480/1000\n",
      "Loss decreases to  0.09744617266285917\n",
      "Epoch 481/1000\n",
      "Loss decreases to  0.09734741622632402\n",
      "Epoch 482/1000\n",
      "Loss decreases to  0.09724896715153218\n",
      "Epoch 483/1000\n",
      "Loss decreases to  0.09715082389369747\n",
      "Epoch 484/1000\n",
      "Loss decreases to  0.09705298491869312\n",
      "Epoch 485/1000\n",
      "Loss decreases to  0.09695544870295937\n",
      "Epoch 486/1000\n",
      "Loss decreases to  0.09685821373341136\n",
      "Epoch 487/1000\n",
      "Loss decreases to  0.09676127850734846\n",
      "Epoch 488/1000\n",
      "Loss decreases to  0.09666464153236402\n",
      "Epoch 489/1000\n",
      "Loss decreases to  0.09656830132625689\n",
      "Epoch 490/1000\n",
      "Loss decreases to  0.0964722564169428\n",
      "Epoch 491/1000\n",
      "Loss decreases to  0.09637650534236764\n",
      "Epoch 492/1000\n",
      "Loss decreases to  0.09628104665042085\n",
      "Epoch 493/1000\n",
      "Loss decreases to  0.09618587889885026\n",
      "Epoch 494/1000\n",
      "Loss decreases to  0.09609100065517755\n",
      "Epoch 495/1000\n",
      "Loss decreases to  0.09599641049661459\n",
      "Epoch 496/1000\n",
      "Loss decreases to  0.09590210700998064\n",
      "Epoch 497/1000\n",
      "Loss decreases to  0.09580808879162057\n",
      "Epoch 498/1000\n",
      "Loss decreases to  0.09571435444732355\n",
      "Epoch 499/1000\n",
      "Loss decreases to  0.09562090259224301\n",
      "Epoch 500/1000\n",
      "Loss decreases to  0.09552773185081705\n",
      "Epoch 501/1000\n",
      "Loss decreases to  0.09543484085668986\n",
      "Epoch 502/1000\n",
      "Loss decreases to  0.09534222825263394\n",
      "Epoch 503/1000\n",
      "Loss decreases to  0.09524989269047293\n",
      "Epoch 504/1000\n",
      "Loss decreases to  0.09515783283100543\n",
      "Epoch 505/1000\n",
      "Loss decreases to  0.09506604734392957\n",
      "Epoch 506/1000\n",
      "Loss decreases to  0.0949745349077681\n",
      "Epoch 507/1000\n",
      "Loss decreases to  0.09488329420979448\n",
      "Epoch 508/1000\n",
      "Loss decreases to  0.0947923239459598\n",
      "Epoch 509/1000\n",
      "Loss decreases to  0.09470162282082001\n",
      "Epoch 510/1000\n",
      "Loss decreases to  0.09461118954746443\n",
      "Epoch 511/1000\n",
      "Loss decreases to  0.09452102284744443\n",
      "Epoch 512/1000\n",
      "Loss decreases to  0.0944311214507032\n",
      "Epoch 513/1000\n",
      "Loss decreases to  0.0943414840955062\n",
      "Epoch 514/1000\n",
      "Loss decreases to  0.09425210952837207\n",
      "Epoch 515/1000\n",
      "Loss decreases to  0.09416299650400436\n",
      "Epoch 516/1000\n",
      "Loss decreases to  0.09407414378522409\n",
      "Epoch 517/1000\n",
      "Loss decreases to  0.09398555014290266\n",
      "Epoch 518/1000\n",
      "Loss decreases to  0.09389721435589574\n",
      "Epoch 519/1000\n",
      "Loss decreases to  0.09380913521097752\n",
      "Epoch 520/1000\n",
      "Loss decreases to  0.09372131150277593\n",
      "Epoch 521/1000\n",
      "Loss decreases to  0.09363374203370814\n",
      "Epoch 522/1000\n",
      "Loss decreases to  0.09354642561391716\n",
      "Epoch 523/1000\n",
      "Loss decreases to  0.09345936106120832\n",
      "Epoch 524/1000\n",
      "Loss decreases to  0.09337254720098738\n",
      "Epoch 525/1000\n",
      "Loss decreases to  0.09328598286619827\n",
      "Epoch 526/1000\n",
      "Loss decreases to  0.09319966689726215\n",
      "Epoch 527/1000\n",
      "Loss decreases to  0.0931135981420165\n",
      "Epoch 528/1000\n",
      "Loss decreases to  0.09302777545565552\n",
      "Epoch 529/1000\n",
      "Loss decreases to  0.09294219770067012\n",
      "Epoch 530/1000\n",
      "Loss decreases to  0.09285686374678956\n",
      "Epoch 531/1000\n",
      "Loss decreases to  0.09277177247092289\n",
      "Epoch 532/1000\n",
      "Loss decreases to  0.09268692275710111\n",
      "Epoch 533/1000\n",
      "Loss decreases to  0.09260231349642029\n",
      "Epoch 534/1000\n",
      "Loss decreases to  0.09251794358698481\n",
      "Epoch 535/1000\n",
      "Loss decreases to  0.09243381193385107\n",
      "Epoch 536/1000\n",
      "Loss decreases to  0.09234991744897228\n",
      "Epoch 537/1000\n",
      "Loss decreases to  0.09226625905114326\n",
      "Epoch 538/1000\n",
      "Loss decreases to  0.09218283566594597\n",
      "Epoch 539/1000\n",
      "Loss decreases to  0.09209964622569557\n",
      "Epoch 540/1000\n",
      "Loss decreases to  0.09201668966938704\n",
      "Epoch 541/1000\n",
      "Loss decreases to  0.0919339649426422\n",
      "Epoch 542/1000\n",
      "Loss decreases to  0.09185147099765711\n",
      "Epoch 543/1000\n",
      "Loss decreases to  0.09176920679315052\n",
      "Epoch 544/1000\n",
      "Loss decreases to  0.09168717129431198\n",
      "Epoch 545/1000\n",
      "Loss decreases to  0.09160536347275132\n",
      "Epoch 546/1000\n",
      "Loss decreases to  0.09152378230644781\n",
      "Epoch 547/1000\n",
      "Loss decreases to  0.09144242677970046\n",
      "Epoch 548/1000\n",
      "Loss decreases to  0.09136129588307841\n",
      "Epoch 549/1000\n",
      "Loss decreases to  0.09128038861337166\n",
      "Epoch 550/1000\n",
      "Loss decreases to  0.09119970397354284\n",
      "Epoch 551/1000\n",
      "Loss decreases to  0.09111924097267889\n",
      "Epoch 552/1000\n",
      "Loss decreases to  0.09103899862594332\n",
      "Epoch 553/1000\n",
      "Loss decreases to  0.09095897595452913\n",
      "Epoch 554/1000\n",
      "Loss decreases to  0.09087917198561188\n",
      "Epoch 555/1000\n",
      "Loss decreases to  0.09079958575230347\n",
      "Epoch 556/1000\n",
      "Loss decreases to  0.09072021629360599\n",
      "Epoch 557/1000\n",
      "Loss decreases to  0.0906410626543666\n",
      "Epoch 558/1000\n",
      "Loss decreases to  0.09056212388523203\n",
      "Epoch 559/1000\n",
      "Loss decreases to  0.09048339904260419\n",
      "Epoch 560/1000\n",
      "Loss decreases to  0.09040488718859593\n",
      "Epoch 561/1000\n",
      "Loss decreases to  0.09032658739098709\n",
      "Epoch 562/1000\n",
      "Loss decreases to  0.09024849872318112\n",
      "Epoch 563/1000\n",
      "Loss decreases to  0.09017062026416212\n",
      "Epoch 564/1000\n",
      "Loss decreases to  0.09009295109845206\n",
      "Epoch 565/1000\n",
      "Loss decreases to  0.09001549031606874\n",
      "Epoch 566/1000\n",
      "Loss decreases to  0.08993823701248385\n",
      "Epoch 567/1000\n",
      "Loss decreases to  0.08986119028858132\n",
      "Epoch 568/1000\n",
      "Loss decreases to  0.0897843492506167\n",
      "Epoch 569/1000\n",
      "Loss decreases to  0.0897077130101759\n",
      "Epoch 570/1000\n",
      "Loss decreases to  0.08963128068413526\n",
      "Epoch 571/1000\n",
      "Loss decreases to  0.08955505139462137\n",
      "Epoch 572/1000\n",
      "Loss decreases to  0.08947902426897163\n",
      "Epoch 573/1000\n",
      "Loss decreases to  0.08940319843969476\n",
      "Epoch 574/1000\n",
      "Loss decreases to  0.08932757304443216\n",
      "Epoch 575/1000\n",
      "Loss decreases to  0.0892521472259192\n",
      "Epoch 576/1000\n",
      "Loss decreases to  0.08917692013194718\n",
      "Epoch 577/1000\n",
      "Loss decreases to  0.08910189091532532\n",
      "Epoch 578/1000\n",
      "Loss decreases to  0.08902705873384334\n",
      "Epoch 579/1000\n",
      "Loss decreases to  0.08895242275023439\n",
      "Epoch 580/1000\n",
      "Loss decreases to  0.08887798213213804\n",
      "Epoch 581/1000\n",
      "Loss decreases to  0.0888037360520639\n",
      "Epoch 582/1000\n",
      "Loss decreases to  0.08872968368735544\n",
      "Epoch 583/1000\n",
      "Loss decreases to  0.08865582422015399\n",
      "Epoch 584/1000\n",
      "Loss decreases to  0.08858215683736353\n",
      "Epoch 585/1000\n",
      "Loss decreases to  0.08850868073061519\n",
      "Epoch 586/1000\n",
      "Loss decreases to  0.08843539509623245\n",
      "Epoch 587/1000\n",
      "Loss decreases to  0.08836229913519647\n",
      "Epoch 588/1000\n",
      "Loss decreases to  0.08828939205311213\n",
      "Epoch 589/1000\n",
      "Loss decreases to  0.08821667306017358\n",
      "Epoch 590/1000\n",
      "Loss decreases to  0.08814414137113094\n",
      "Epoch 591/1000\n",
      "Loss decreases to  0.0880717962052568\n",
      "Epoch 592/1000\n",
      "Loss decreases to  0.08799963678631306\n",
      "Epoch 593/1000\n",
      "Loss decreases to  0.08792766234251827\n",
      "Epoch 594/1000\n",
      "Loss decreases to  0.08785587210651505\n",
      "Epoch 595/1000\n",
      "Loss decreases to  0.08778426531533794\n",
      "Epoch 596/1000\n",
      "Loss decreases to  0.08771284121038132\n",
      "Epoch 597/1000\n",
      "Loss decreases to  0.08764159903736805\n",
      "Epoch 598/1000\n",
      "Loss decreases to  0.0875705380463178\n",
      "Epoch 599/1000\n",
      "Loss decreases to  0.08749965749151603\n",
      "Epoch 600/1000\n",
      "Loss decreases to  0.08742895663148335\n",
      "Epoch 601/1000\n",
      "Loss decreases to  0.08735843472894465\n",
      "Epoch 602/1000\n",
      "Loss decreases to  0.08728809105079902\n",
      "Epoch 603/1000\n",
      "Loss decreases to  0.08721792486808977\n",
      "Epoch 604/1000\n",
      "Loss decreases to  0.08714793545597445\n",
      "Epoch 605/1000\n",
      "Loss decreases to  0.08707812209369548\n",
      "Epoch 606/1000\n",
      "Loss decreases to  0.08700848406455082\n",
      "Epoch 607/1000\n",
      "Loss decreases to  0.08693902065586509\n",
      "Epoch 608/1000\n",
      "Loss decreases to  0.08686973115896074\n",
      "Epoch 609/1000\n",
      "Loss decreases to  0.08680061486912949\n",
      "Epoch 610/1000\n",
      "Loss decreases to  0.08673167108560419\n",
      "Epoch 611/1000\n",
      "Loss decreases to  0.08666289911153068\n",
      "Epoch 612/1000\n",
      "Loss decreases to  0.08659429825394016\n",
      "Epoch 613/1000\n",
      "Loss decreases to  0.08652586782372149\n",
      "Epoch 614/1000\n",
      "Loss decreases to  0.08645760713559403\n",
      "Epoch 615/1000\n",
      "Loss decreases to  0.08638951550808052\n",
      "Epoch 616/1000\n",
      "Loss decreases to  0.08632159226348013\n",
      "Epoch 617/1000\n",
      "Loss decreases to  0.08625383672784216\n",
      "Epoch 618/1000\n",
      "Loss decreases to  0.08618624823093922\n",
      "Epoch 619/1000\n",
      "Loss decreases to  0.08611882610624148\n",
      "Epoch 620/1000\n",
      "Loss decreases to  0.08605156969089046\n",
      "Epoch 621/1000\n",
      "Loss decreases to  0.08598447832567349\n",
      "Epoch 622/1000\n",
      "Loss decreases to  0.08591755135499812\n",
      "Epoch 623/1000\n",
      "Loss decreases to  0.08585078812686685\n",
      "Epoch 624/1000\n",
      "Loss decreases to  0.085784187992852\n",
      "Epoch 625/1000\n",
      "Loss decreases to  0.085717750308071\n",
      "Epoch 626/1000\n",
      "Loss decreases to  0.08565147443116164\n",
      "Epoch 627/1000\n",
      "Loss decreases to  0.08558535972425758\n",
      "Epoch 628/1000\n",
      "Loss decreases to  0.08551940555296425\n",
      "Epoch 629/1000\n",
      "Loss decreases to  0.08545361128633476\n",
      "Epoch 630/1000\n",
      "Loss decreases to  0.08538797629684602\n",
      "Epoch 631/1000\n",
      "Loss decreases to  0.08532249996037504\n",
      "Epoch 632/1000\n",
      "Loss decreases to  0.08525718165617571\n",
      "Epoch 633/1000\n",
      "Loss decreases to  0.08519202076685543\n",
      "Epoch 634/1000\n",
      "Loss decreases to  0.08512701667835201\n",
      "Epoch 635/1000\n",
      "Loss decreases to  0.08506216877991091\n",
      "Epoch 636/1000\n",
      "Loss decreases to  0.0849974764640625\n",
      "Epoch 637/1000\n",
      "Loss decreases to  0.08493293912659965\n",
      "Epoch 638/1000\n",
      "Loss decreases to  0.08486855616655538\n",
      "Epoch 639/1000\n",
      "Loss decreases to  0.08480432698618075\n",
      "Epoch 640/1000\n",
      "Loss decreases to  0.08474025099092304\n",
      "Epoch 641/1000\n",
      "Loss decreases to  0.0846763275894038\n",
      "Epoch 642/1000\n",
      "Loss decreases to  0.08461255619339747\n",
      "Epoch 643/1000\n",
      "Loss decreases to  0.08454893621780994\n",
      "Epoch 644/1000\n",
      "Loss decreases to  0.08448546708065725\n",
      "Epoch 645/1000\n",
      "Loss decreases to  0.08442214820304464\n",
      "Epoch 646/1000\n",
      "Loss decreases to  0.08435897900914573\n",
      "Epoch 647/1000\n",
      "Loss decreases to  0.08429595892618158\n",
      "Epoch 648/1000\n",
      "Loss decreases to  0.08423308738440048\n",
      "Epoch 649/1000\n",
      "Loss decreases to  0.08417036381705734\n",
      "Epoch 650/1000\n",
      "Loss decreases to  0.08410778766039365\n",
      "Epoch 651/1000\n",
      "Loss decreases to  0.08404535835361733\n",
      "Epoch 652/1000\n",
      "Loss decreases to  0.08398307533888295\n",
      "Epoch 653/1000\n",
      "Loss decreases to  0.08392093806127202\n",
      "Epoch 654/1000\n",
      "Loss decreases to  0.08385894596877327\n",
      "Epoch 655/1000\n",
      "Loss decreases to  0.08379709851226355\n",
      "Epoch 656/1000\n",
      "Loss decreases to  0.08373539514548833\n",
      "Epoch 657/1000\n",
      "Loss decreases to  0.08367383532504286\n",
      "Epoch 658/1000\n",
      "Loss decreases to  0.08361241851035292\n",
      "Epoch 659/1000\n",
      "Loss decreases to  0.08355114416365635\n",
      "Epoch 660/1000\n",
      "Loss decreases to  0.08349001174998434\n",
      "Epoch 661/1000\n",
      "Loss decreases to  0.08342902073714287\n",
      "Epoch 662/1000\n",
      "Loss decreases to  0.08336817059569444\n",
      "Epoch 663/1000\n",
      "Loss decreases to  0.08330746079893996\n",
      "Epoch 664/1000\n",
      "Loss decreases to  0.08324689082290053\n",
      "Epoch 665/1000\n",
      "Loss decreases to  0.08318646014629975\n",
      "Epoch 666/1000\n",
      "Loss decreases to  0.08312616825054585\n",
      "Epoch 667/1000\n",
      "Loss decreases to  0.08306601461971415\n",
      "Epoch 668/1000\n",
      "Loss decreases to  0.08300599874052948\n",
      "Epoch 669/1000\n",
      "Loss decreases to  0.08294612010234902\n",
      "Epoch 670/1000\n",
      "Loss decreases to  0.08288637819714492\n",
      "Epoch 671/1000\n",
      "Loss decreases to  0.08282677251948746\n",
      "Epoch 672/1000\n",
      "Loss decreases to  0.08276730256652791\n",
      "Epoch 673/1000\n",
      "Loss decreases to  0.08270796783798179\n",
      "Epoch 674/1000\n",
      "Loss decreases to  0.08264876783611244\n",
      "Epoch 675/1000\n",
      "Loss decreases to  0.08258970206571419\n",
      "Epoch 676/1000\n",
      "Loss decreases to  0.08253077003409602\n",
      "Epoch 677/1000\n",
      "Loss decreases to  0.08247197125106549\n",
      "Epoch 678/1000\n",
      "Loss decreases to  0.08241330522891244\n",
      "Epoch 679/1000\n",
      "Loss decreases to  0.08235477148239304\n",
      "Epoch 680/1000\n",
      "Loss decreases to  0.08229636952871368\n",
      "Epoch 681/1000\n",
      "Loss decreases to  0.08223809888751568\n",
      "Epoch 682/1000\n",
      "Loss decreases to  0.08217995908085918\n",
      "Epoch 683/1000\n",
      "Loss decreases to  0.08212194963320782\n",
      "Epoch 684/1000\n",
      "Loss decreases to  0.08206407007141332\n",
      "Epoch 685/1000\n",
      "Loss decreases to  0.08200631992470032\n",
      "Epoch 686/1000\n",
      "Loss decreases to  0.08194869872465098\n",
      "Epoch 687/1000\n",
      "Loss decreases to  0.08189120600519009\n",
      "Epoch 688/1000\n",
      "Loss decreases to  0.08183384130257007\n",
      "Epoch 689/1000\n",
      "Loss decreases to  0.08177660415535633\n",
      "Epoch 690/1000\n",
      "Loss decreases to  0.0817194941044122\n",
      "Epoch 691/1000\n",
      "Loss decreases to  0.08166251069288485\n",
      "Epoch 692/1000\n",
      "Loss decreases to  0.08160565346619039\n",
      "Epoch 693/1000\n",
      "Loss decreases to  0.0815489219719997\n",
      "Epoch 694/1000\n",
      "Loss decreases to  0.08149231576022417\n",
      "Epoch 695/1000\n",
      "Loss decreases to  0.08143583438300148\n",
      "Epoch 696/1000\n",
      "Loss decreases to  0.08137947739468165\n",
      "Epoch 697/1000\n",
      "Loss decreases to  0.08132324435181304\n",
      "Epoch 698/1000\n",
      "Loss decreases to  0.08126713481312868\n",
      "Epoch 699/1000\n",
      "Loss decreases to  0.08121114833953233\n",
      "Epoch 700/1000\n",
      "Loss decreases to  0.08115528449408499\n",
      "Epoch 701/1000\n",
      "Loss decreases to  0.0810995428419914\n",
      "Epoch 702/1000\n",
      "Loss decreases to  0.08104392295058668\n",
      "Epoch 703/1000\n",
      "Loss decreases to  0.08098842438932286\n",
      "Epoch 704/1000\n",
      "Loss decreases to  0.08093304672975579\n",
      "Epoch 705/1000\n",
      "Loss decreases to  0.08087778954553211\n",
      "Epoch 706/1000\n",
      "Loss decreases to  0.080822652412376\n",
      "Epoch 707/1000\n",
      "Loss decreases to  0.08076763490807663\n",
      "Epoch 708/1000\n",
      "Loss decreases to  0.08071273661247502\n",
      "Epoch 709/1000\n",
      "Loss decreases to  0.08065795710745147\n",
      "Epoch 710/1000\n",
      "Loss decreases to  0.08060329597691296\n",
      "Epoch 711/1000\n",
      "Loss decreases to  0.0805487528067806\n",
      "Epoch 712/1000\n",
      "Loss decreases to  0.08049432718497715\n",
      "Epoch 713/1000\n",
      "Loss decreases to  0.08044001870141476\n",
      "Epoch 714/1000\n",
      "Loss decreases to  0.08038582694798274\n",
      "Epoch 715/1000\n",
      "Loss decreases to  0.08033175151853532\n",
      "Epoch 716/1000\n",
      "Loss decreases to  0.08027779200887955\n",
      "Epoch 717/1000\n",
      "Loss decreases to  0.08022394801676355\n",
      "Epoch 718/1000\n",
      "Loss decreases to  0.08017021914186442\n",
      "Epoch 719/1000\n",
      "Loss decreases to  0.0801166049857765\n",
      "Epoch 720/1000\n",
      "Loss decreases to  0.08006310515199967\n",
      "Epoch 721/1000\n",
      "Loss decreases to  0.08000971924592779\n",
      "Epoch 722/1000\n",
      "Loss decreases to  0.07995644687483697\n",
      "Epoch 723/1000\n",
      "Loss decreases to  0.07990328764787434\n",
      "Epoch 724/1000\n",
      "Loss decreases to  0.07985024117604665\n",
      "Epoch 725/1000\n",
      "Loss decreases to  0.0797973070722088\n",
      "Epoch 726/1000\n",
      "Loss decreases to  0.07974448495105294\n",
      "Epoch 727/1000\n",
      "Loss decreases to  0.07969177442909699\n",
      "Epoch 728/1000\n",
      "Loss decreases to  0.07963917512467397\n",
      "Epoch 729/1000\n",
      "Loss decreases to  0.07958668665792076\n",
      "Epoch 730/1000\n",
      "Loss decreases to  0.07953430865076748\n",
      "Epoch 731/1000\n",
      "Loss decreases to  0.07948204072692645\n",
      "Epoch 732/1000\n",
      "Loss decreases to  0.07942988251188157\n",
      "Epoch 733/1000\n",
      "Loss decreases to  0.0793778336328778\n",
      "Epoch 734/1000\n",
      "Loss decreases to  0.07932589371891036\n",
      "Epoch 735/1000\n",
      "Loss decreases to  0.07927406240071448\n",
      "Epoch 736/1000\n",
      "Loss decreases to  0.07922233931075491\n",
      "Epoch 737/1000\n",
      "Loss decreases to  0.07917072408321546\n",
      "Epoch 738/1000\n",
      "Loss decreases to  0.07911921635398897\n",
      "Epoch 739/1000\n",
      "Loss decreases to  0.07906781576066692\n",
      "Epoch 740/1000\n",
      "Loss decreases to  0.0790165219425295\n",
      "Epoch 741/1000\n",
      "Loss decreases to  0.07896533454053542\n",
      "Epoch 742/1000\n",
      "Loss decreases to  0.07891425319731203\n",
      "Epoch 743/1000\n",
      "Loss decreases to  0.07886327755714544\n",
      "Epoch 744/1000\n",
      "Loss decreases to  0.07881240726597061\n",
      "Epoch 745/1000\n",
      "Loss decreases to  0.07876164197136168\n",
      "Epoch 746/1000\n",
      "Loss decreases to  0.07871098132252236\n",
      "Epoch 747/1000\n",
      "Loss decreases to  0.07866042497027609\n",
      "Epoch 748/1000\n",
      "Loss decreases to  0.07860997256705667\n",
      "Epoch 749/1000\n",
      "Loss decreases to  0.07855962376689879\n",
      "Epoch 750/1000\n",
      "Loss decreases to  0.07850937822542861\n",
      "Epoch 751/1000\n",
      "Loss decreases to  0.07845923559985431\n",
      "Epoch 752/1000\n",
      "Loss decreases to  0.07840919554895694\n",
      "Epoch 753/1000\n",
      "Loss decreases to  0.07835925773308118\n",
      "Epoch 754/1000\n",
      "Loss decreases to  0.07830942181412621\n",
      "Epoch 755/1000\n",
      "Loss decreases to  0.07825968745553655\n",
      "Epoch 756/1000\n",
      "Loss decreases to  0.0782100543222932\n",
      "Epoch 757/1000\n",
      "Loss decreases to  0.07816052208090452\n",
      "Epoch 758/1000\n",
      "Loss decreases to  0.07811109039939751\n",
      "Epoch 759/1000\n",
      "Loss decreases to  0.07806175894730881\n",
      "Epoch 760/1000\n",
      "Loss decreases to  0.07801252739567616\n",
      "Epoch 761/1000\n",
      "Loss decreases to  0.07796339541702944\n",
      "Epoch 762/1000\n",
      "Loss decreases to  0.07791436268538228\n",
      "Epoch 763/1000\n",
      "Loss decreases to  0.07786542887622334\n",
      "Epoch 764/1000\n",
      "Loss decreases to  0.07781659366650778\n",
      "Epoch 765/1000\n",
      "Loss decreases to  0.07776785673464888\n",
      "Epoch 766/1000\n",
      "Loss decreases to  0.07771921776050965\n",
      "Epoch 767/1000\n",
      "Loss decreases to  0.07767067642539442\n",
      "Epoch 768/1000\n",
      "Loss decreases to  0.0776222324120405\n",
      "Epoch 769/1000\n",
      "Loss decreases to  0.07757388540461024\n",
      "Epoch 770/1000\n",
      "Loss decreases to  0.07752563508868245\n",
      "Epoch 771/1000\n",
      "Loss decreases to  0.07747748115124471\n",
      "Epoch 772/1000\n",
      "Loss decreases to  0.07742942328068499\n",
      "Epoch 773/1000\n",
      "Loss decreases to  0.07738146116678384\n",
      "Epoch 774/1000\n",
      "Loss decreases to  0.07733359450070636\n",
      "Epoch 775/1000\n",
      "Loss decreases to  0.07728582297499437\n",
      "Epoch 776/1000\n",
      "Loss decreases to  0.07723814628355855\n",
      "Epoch 777/1000\n",
      "Loss decreases to  0.07719056412167062\n",
      "Epoch 778/1000\n",
      "Loss decreases to  0.07714307618595573\n",
      "Epoch 779/1000\n",
      "Loss decreases to  0.07709568217438462\n",
      "Epoch 780/1000\n",
      "Loss decreases to  0.07704838178626626\n",
      "Epoch 781/1000\n",
      "Loss decreases to  0.07700117472223997\n",
      "Epoch 782/1000\n",
      "Loss decreases to  0.07695406068426808\n",
      "Epoch 783/1000\n",
      "Loss decreases to  0.07690703937562854\n",
      "Epoch 784/1000\n",
      "Loss decreases to  0.07686011050090734\n",
      "Epoch 785/1000\n",
      "Loss decreases to  0.07681327376599129\n",
      "Epoch 786/1000\n",
      "Loss decreases to  0.07676652887806056\n",
      "Epoch 787/1000\n",
      "Loss decreases to  0.07671987554558155\n",
      "Epoch 788/1000\n",
      "Loss decreases to  0.07667331347829962\n",
      "Epoch 789/1000\n",
      "Loss decreases to  0.07662684238723204\n",
      "Epoch 790/1000\n",
      "Loss decreases to  0.07658046198466063\n",
      "Epoch 791/1000\n",
      "Loss decreases to  0.07653417198412493\n",
      "Epoch 792/1000\n",
      "Loss decreases to  0.07648797210041505\n",
      "Epoch 793/1000\n",
      "Loss decreases to  0.07644186204956487\n",
      "Epoch 794/1000\n",
      "Loss decreases to  0.07639584154884482\n",
      "Epoch 795/1000\n",
      "Loss decreases to  0.0763499103167553\n",
      "Epoch 796/1000\n",
      "Loss decreases to  0.0763040680730197\n",
      "Epoch 797/1000\n",
      "Loss decreases to  0.07625831453857763\n",
      "Epoch 798/1000\n",
      "Loss decreases to  0.07621264943557825\n",
      "Epoch 799/1000\n",
      "Loss decreases to  0.07616707248737353\n",
      "Epoch 800/1000\n",
      "Loss decreases to  0.07612158341851148\n",
      "Epoch 801/1000\n",
      "Loss decreases to  0.07607618195472984\n",
      "Epoch 802/1000\n",
      "Loss decreases to  0.07603086782294927\n",
      "Epoch 803/1000\n",
      "Loss decreases to  0.07598564075126692\n",
      "Epoch 804/1000\n",
      "Loss decreases to  0.0759405004689499\n",
      "Epoch 805/1000\n",
      "Loss decreases to  0.07589544670642911\n",
      "Epoch 806/1000\n",
      "Loss decreases to  0.07585047919529239\n",
      "Epoch 807/1000\n",
      "Loss decreases to  0.07580559766827868\n",
      "Epoch 808/1000\n",
      "Loss decreases to  0.07576080185927135\n",
      "Epoch 809/1000\n",
      "Loss decreases to  0.07571609150329209\n",
      "Epoch 810/1000\n",
      "Loss decreases to  0.0756714663364947\n",
      "Epoch 811/1000\n",
      "Loss decreases to  0.07562692609615893\n",
      "Epoch 812/1000\n",
      "Loss decreases to  0.07558247052068423\n",
      "Epoch 813/1000\n",
      "Loss decreases to  0.07553809934958378\n",
      "Epoch 814/1000\n",
      "Loss decreases to  0.07549381232347845\n",
      "Epoch 815/1000\n",
      "Loss decreases to  0.07544960918409066\n",
      "Epoch 816/1000\n",
      "Loss decreases to  0.07540548967423848\n",
      "Epoch 817/1000\n",
      "Loss decreases to  0.07536145353782979\n",
      "Epoch 818/1000\n",
      "Loss decreases to  0.0753175005198561\n",
      "Epoch 819/1000\n",
      "Loss decreases to  0.0752736303663871\n",
      "Epoch 820/1000\n",
      "Loss decreases to  0.07522984282456445\n",
      "Epoch 821/1000\n",
      "Loss decreases to  0.07518613764259632\n",
      "Epoch 822/1000\n",
      "Loss decreases to  0.07514251456975136\n",
      "Epoch 823/1000\n",
      "Loss decreases to  0.0750989733563532\n",
      "Epoch 824/1000\n",
      "Loss decreases to  0.07505551375377481\n",
      "Epoch 825/1000\n",
      "Loss decreases to  0.07501213551443267\n",
      "Epoch 826/1000\n",
      "Loss decreases to  0.07496883839178127\n",
      "Epoch 827/1000\n",
      "Loss decreases to  0.07492562214030767\n",
      "Epoch 828/1000\n",
      "Loss decreases to  0.07488248651552579\n",
      "Epoch 829/1000\n",
      "Loss decreases to  0.07483943127397111\n",
      "Epoch 830/1000\n",
      "Loss decreases to  0.07479645617319503\n",
      "Epoch 831/1000\n",
      "Loss decreases to  0.0747535609717596\n",
      "Epoch 832/1000\n",
      "Loss decreases to  0.07471074542923208\n",
      "Epoch 833/1000\n",
      "Loss decreases to  0.07466800930617969\n",
      "Epoch 834/1000\n",
      "Loss decreases to  0.07462535236416402\n",
      "Epoch 835/1000\n",
      "Loss decreases to  0.07458277436573618\n",
      "Epoch 836/1000\n",
      "Loss decreases to  0.0745402750744312\n",
      "Epoch 837/1000\n",
      "Loss decreases to  0.074497854254763\n",
      "Epoch 838/1000\n",
      "Loss decreases to  0.07445551167221914\n",
      "Epoch 839/1000\n",
      "Loss decreases to  0.07441324709325574\n",
      "Epoch 840/1000\n",
      "Loss decreases to  0.07437106028529233\n",
      "Epoch 841/1000\n",
      "Loss decreases to  0.07432895101670678\n",
      "Epoch 842/1000\n",
      "Loss decreases to  0.07428691905683028\n",
      "Epoch 843/1000\n",
      "Loss decreases to  0.07424496417594231\n",
      "Epoch 844/1000\n",
      "Loss decreases to  0.07420308614526562\n",
      "Epoch 845/1000\n",
      "Loss decreases to  0.07416128473696147\n",
      "Epoch 846/1000\n",
      "Loss decreases to  0.07411955972412437\n",
      "Epoch 847/1000\n",
      "Loss decreases to  0.07407791088077759\n",
      "Epoch 848/1000\n",
      "Loss decreases to  0.07403633798186798\n",
      "Epoch 849/1000\n",
      "Loss decreases to  0.07399484080326137\n",
      "Epoch 850/1000\n",
      "Loss decreases to  0.07395341912173761\n",
      "Epoch 851/1000\n",
      "Loss decreases to  0.07391207271498604\n",
      "Epoch 852/1000\n",
      "Loss decreases to  0.07387080136160044\n",
      "Epoch 853/1000\n",
      "Loss decreases to  0.07382960484107465\n",
      "Epoch 854/1000\n",
      "Loss decreases to  0.07378848293379764\n",
      "Epoch 855/1000\n",
      "Loss decreases to  0.073747435421049\n",
      "Epoch 856/1000\n",
      "Loss decreases to  0.07370646208499436\n",
      "Epoch 857/1000\n",
      "Loss decreases to  0.07366556270868073\n",
      "Epoch 858/1000\n",
      "Loss decreases to  0.07362473707603193\n",
      "Epoch 859/1000\n",
      "Loss decreases to  0.07358398497184414\n",
      "Epoch 860/1000\n",
      "Loss decreases to  0.07354330618178143\n",
      "Epoch 861/1000\n",
      "Loss decreases to  0.07350270049237102\n",
      "Epoch 862/1000\n",
      "Loss decreases to  0.07346216769099931\n",
      "Epoch 863/1000\n",
      "Loss decreases to  0.07342170756590698\n",
      "Epoch 864/1000\n",
      "Loss decreases to  0.07338131990618496\n",
      "Epoch 865/1000\n",
      "Loss decreases to  0.07334100450176986\n",
      "Epoch 866/1000\n",
      "Loss decreases to  0.07330076114343978\n",
      "Epoch 867/1000\n",
      "Loss decreases to  0.07326058962280987\n",
      "Epoch 868/1000\n",
      "Loss decreases to  0.0732204897323282\n",
      "Epoch 869/1000\n",
      "Loss decreases to  0.07318046126527133\n",
      "Epoch 870/1000\n",
      "Loss decreases to  0.07314050401574027\n",
      "Epoch 871/1000\n",
      "Loss decreases to  0.07310061777865617\n",
      "Epoch 872/1000\n",
      "Loss decreases to  0.07306080234975625\n",
      "Epoch 873/1000\n",
      "Loss decreases to  0.07302105752558939\n",
      "Epoch 874/1000\n",
      "Loss decreases to  0.07298138310351239\n",
      "Epoch 875/1000\n",
      "Loss decreases to  0.07294177888168554\n",
      "Epoch 876/1000\n",
      "Loss decreases to  0.07290224465906883\n",
      "Epoch 877/1000\n",
      "Loss decreases to  0.07286278023541766\n",
      "Epoch 878/1000\n",
      "Loss decreases to  0.07282338541127897\n",
      "Epoch 879/1000\n",
      "Loss decreases to  0.0727840599879872\n",
      "Epoch 880/1000\n",
      "Loss decreases to  0.07274480376766027\n",
      "Epoch 881/1000\n",
      "Loss decreases to  0.07270561655319573\n",
      "Epoch 882/1000\n",
      "Loss decreases to  0.07266649814826678\n",
      "Epoch 883/1000\n",
      "Loss decreases to  0.0726274483573184\n",
      "Epoch 884/1000\n",
      "Loss decreases to  0.0725884669855634\n",
      "Epoch 885/1000\n",
      "Loss decreases to  0.07254955383897867\n",
      "Epoch 886/1000\n",
      "Loss decreases to  0.0725107087243013\n",
      "Epoch 887/1000\n",
      "Loss decreases to  0.07247193144902482\n",
      "Epoch 888/1000\n",
      "Loss decreases to  0.0724332218213952\n",
      "Epoch 889/1000\n",
      "Loss decreases to  0.0723945796504076\n",
      "Epoch 890/1000\n",
      "Loss decreases to  0.07235600474580192\n",
      "Epoch 891/1000\n",
      "Loss decreases to  0.07231749691805979\n",
      "Epoch 892/1000\n",
      "Loss decreases to  0.07227905597840045\n",
      "Epoch 893/1000\n",
      "Loss decreases to  0.07224068173877711\n",
      "Epoch 894/1000\n",
      "Loss decreases to  0.07220237401187356\n",
      "Epoch 895/1000\n",
      "Loss decreases to  0.07216413261110022\n",
      "Epoch 896/1000\n",
      "Loss decreases to  0.0721259573505908\n",
      "Epoch 897/1000\n",
      "Loss decreases to  0.07208784804519859\n",
      "Epoch 898/1000\n",
      "Loss decreases to  0.07204980451049285\n",
      "Epoch 899/1000\n",
      "Loss decreases to  0.07201182656275544\n",
      "Epoch 900/1000\n",
      "Loss decreases to  0.07197391401897724\n",
      "Epoch 901/1000\n",
      "Loss decreases to  0.07193606669685451\n",
      "Epoch 902/1000\n",
      "Loss decreases to  0.07189828441478562\n",
      "Epoch 903/1000\n",
      "Loss decreases to  0.07186056699186749\n",
      "Epoch 904/1000\n",
      "Loss decreases to  0.07182291424789218\n",
      "Epoch 905/1000\n",
      "Loss decreases to  0.07178532600334343\n",
      "Epoch 906/1000\n",
      "Loss decreases to  0.07174780207939342\n",
      "Epoch 907/1000\n",
      "Loss decreases to  0.07171034229789917\n",
      "Epoch 908/1000\n",
      "Loss decreases to  0.07167294648139945\n",
      "Epoch 909/1000\n",
      "Loss decreases to  0.0716356144531112\n",
      "Epoch 910/1000\n",
      "Loss decreases to  0.07159834603692637\n",
      "Epoch 911/1000\n",
      "Loss decreases to  0.07156114105740857\n",
      "Epoch 912/1000\n",
      "Loss decreases to  0.07152399933978987\n",
      "Epoch 913/1000\n",
      "Loss decreases to  0.07148692070996741\n",
      "Epoch 914/1000\n",
      "Loss decreases to  0.07144990499450038\n",
      "Epoch 915/1000\n",
      "Loss decreases to  0.07141295202060649\n",
      "Epoch 916/1000\n",
      "Loss decreases to  0.0713760616161591\n",
      "Epoch 917/1000\n",
      "Loss decreases to  0.07133923360968387\n",
      "Epoch 918/1000\n",
      "Loss decreases to  0.07130246783035565\n",
      "Epoch 919/1000\n",
      "Loss decreases to  0.07126576410799527\n",
      "Epoch 920/1000\n",
      "Loss decreases to  0.07122912227306655\n",
      "Epoch 921/1000\n",
      "Loss decreases to  0.071192542156673\n",
      "Epoch 922/1000\n",
      "Loss decreases to  0.071156023590555\n",
      "Epoch 923/1000\n",
      "Loss decreases to  0.07111956640708657\n",
      "Epoch 924/1000\n",
      "Loss decreases to  0.07108317043927229\n",
      "Epoch 925/1000\n",
      "Loss decreases to  0.07104683552074424\n",
      "Epoch 926/1000\n",
      "Loss decreases to  0.07101056148575927\n",
      "Epoch 927/1000\n",
      "Loss decreases to  0.07097434816919572\n",
      "Epoch 928/1000\n",
      "Loss decreases to  0.07093819540655043\n",
      "Epoch 929/1000\n",
      "Loss decreases to  0.07090210303393606\n",
      "Epoch 930/1000\n",
      "Loss decreases to  0.07086607088807777\n",
      "Epoch 931/1000\n",
      "Loss decreases to  0.07083009880631068\n",
      "Epoch 932/1000\n",
      "Loss decreases to  0.0707941866265766\n",
      "Epoch 933/1000\n",
      "Loss decreases to  0.07075833418742143\n",
      "Epoch 934/1000\n",
      "Loss decreases to  0.07072254132799212\n",
      "Epoch 935/1000\n",
      "Loss decreases to  0.07068680788803382\n",
      "Epoch 936/1000\n",
      "Loss decreases to  0.07065113370788714\n",
      "Epoch 937/1000\n",
      "Loss decreases to  0.07061551862848518\n",
      "Epoch 938/1000\n",
      "Loss decreases to  0.07057996249135089\n",
      "Epoch 939/1000\n",
      "Loss decreases to  0.07054446513859405\n",
      "Epoch 940/1000\n",
      "Loss decreases to  0.07050902641290879\n",
      "Epoch 941/1000\n",
      "Loss decreases to  0.07047364615757058\n",
      "Epoch 942/1000\n",
      "Loss decreases to  0.07043832421643358\n",
      "Epoch 943/1000\n",
      "Loss decreases to  0.07040306043392783\n",
      "Epoch 944/1000\n",
      "Loss decreases to  0.07036785465505675\n",
      "Epoch 945/1000\n",
      "Loss decreases to  0.07033270672539418\n",
      "Epoch 946/1000\n",
      "Loss decreases to  0.07029761649108193\n",
      "Epoch 947/1000\n",
      "Loss decreases to  0.07026258379882681\n",
      "Epoch 948/1000\n",
      "Loss decreases to  0.07022760849589844\n",
      "Epoch 949/1000\n",
      "Loss decreases to  0.07019269043012609\n",
      "Epoch 950/1000\n",
      "Loss decreases to  0.07015782944989646\n",
      "Epoch 951/1000\n",
      "Loss decreases to  0.07012302540415086\n",
      "Epoch 952/1000\n",
      "Loss decreases to  0.07008827814238269\n",
      "Epoch 953/1000\n",
      "Loss decreases to  0.0700535875146349\n",
      "Epoch 954/1000\n",
      "Loss decreases to  0.0700189533714973\n",
      "Epoch 955/1000\n",
      "Loss decreases to  0.06998437556410408\n",
      "Epoch 956/1000\n",
      "Loss decreases to  0.06994985394413142\n",
      "Epoch 957/1000\n",
      "Loss decreases to  0.06991538836379471\n",
      "Epoch 958/1000\n",
      "Loss decreases to  0.06988097867584622\n",
      "Epoch 959/1000\n",
      "Loss decreases to  0.0698466247335726\n",
      "Epoch 960/1000\n",
      "Loss decreases to  0.06981232639079227\n",
      "Epoch 961/1000\n",
      "Loss decreases to  0.06977808350185316\n",
      "Epoch 962/1000\n",
      "Loss decreases to  0.06974389592163006\n",
      "Epoch 963/1000\n",
      "Loss decreases to  0.06970976350552235\n",
      "Epoch 964/1000\n",
      "Loss decreases to  0.06967568610945149\n",
      "Epoch 965/1000\n",
      "Loss decreases to  0.06964166358985859\n",
      "Epoch 966/1000\n",
      "Loss decreases to  0.06960769580370205\n",
      "Epoch 967/1000\n",
      "Loss decreases to  0.06957378260845527\n",
      "Epoch 968/1000\n",
      "Loss decreases to  0.0695399238621041\n",
      "Epoch 969/1000\n",
      "Loss decreases to  0.06950611942314466\n",
      "Epoch 970/1000\n",
      "Loss decreases to  0.06947236915058087\n",
      "Epoch 971/1000\n",
      "Loss decreases to  0.0694386729039222\n",
      "Epoch 972/1000\n",
      "Loss decreases to  0.06940503054318123\n",
      "Epoch 973/1000\n",
      "Loss decreases to  0.0693714419288716\n",
      "Epoch 974/1000\n",
      "Loss decreases to  0.0693379069220055\n",
      "Epoch 975/1000\n",
      "Loss decreases to  0.06930442538409139\n",
      "Epoch 976/1000\n",
      "Loss decreases to  0.06927099717713191\n",
      "Epoch 977/1000\n",
      "Loss decreases to  0.0692376221636214\n",
      "Epoch 978/1000\n",
      "Loss decreases to  0.06920430020654394\n",
      "Epoch 979/1000\n",
      "Loss decreases to  0.06917103116937083\n",
      "Epoch 980/1000\n",
      "Loss decreases to  0.0691378149160586\n",
      "Epoch 981/1000\n",
      "Loss decreases to  0.06910465131104665\n",
      "Epoch 982/1000\n",
      "Loss decreases to  0.06907154021925521\n",
      "Epoch 983/1000\n",
      "Loss decreases to  0.06903848150608304\n",
      "Epoch 984/1000\n",
      "Loss decreases to  0.06900547503740521\n",
      "Epoch 985/1000\n",
      "Loss decreases to  0.06897252067957127\n",
      "Epoch 986/1000\n",
      "Loss decreases to  0.0689396182994027\n",
      "Epoch 987/1000\n",
      "Loss decreases to  0.06890676776419098\n",
      "Epoch 988/1000\n",
      "Loss decreases to  0.06887396894169556\n",
      "Epoch 989/1000\n",
      "Loss decreases to  0.06884122170014148\n",
      "Epoch 990/1000\n",
      "Loss decreases to  0.06880852590821764\n",
      "Epoch 991/1000\n",
      "Loss decreases to  0.0687758814350743\n",
      "Epoch 992/1000\n",
      "Loss decreases to  0.06874328815032134\n",
      "Epoch 993/1000\n",
      "Loss decreases to  0.06871074592402614\n",
      "Epoch 994/1000\n",
      "Loss decreases to  0.06867825462671137\n",
      "Epoch 995/1000\n",
      "Loss decreases to  0.0686458141293531\n",
      "Epoch 996/1000\n",
      "Loss decreases to  0.06861342430337868\n",
      "Epoch 997/1000\n",
      "Loss decreases to  0.06858108502066486\n",
      "Epoch 998/1000\n",
      "Loss decreases to  0.0685487961535356\n",
      "Epoch 999/1000\n",
      "Loss decreases to  0.0685165575747602\n",
      "Epoch 1000/1000\n",
      "Loss decreases to  0.06848436915755135\n"
     ]
    }
   ],
   "source": [
    "h = LogisticRegression(alpha=LEARNING_RATE, iteration=ITERATIONS)\n",
    "h.fit(X_train, y_train)\n",
    "# y_pred = h.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score we have achieved using Logistic Regression is: 97.32 %\n"
     ]
    }
   ],
   "source": [
    "score = round(h.score(X_test, y_test)*100, 2)\n",
    "print(\"The accuracy score we have achieved using Logistic Regression is: \"+str(score)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, y, 'ro')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.08431984])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.192792541913596"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the probability curve\n",
    "plt.plot(X_test, y_test, 'ro')\n",
    "plt.plot(np.array([np.arange(start=2, stop=8, step=0.01)]).T, h.probability_curve(np.array([np.arange(start=2, stop=8, step=0.01)]).T))\n",
    "plt.xlabel('Total Stat')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
